{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial - 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "- Fundamental block of Machine Learning\n",
    "- Used to represent any data (images for eg) in numerical means\n",
    "\n",
    "For example, an image could be represented as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, width, height]` as in the image has 3 colours channel (RGB), and a width and height of 224 pixels each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars\n",
    "\n",
    "A scaler is a simple number. In tensor talk, it is a zero dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scalar\n",
    "scaler = torch.tensor(7)\n",
    "scaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out tensor(7) indicating that scaler is a single number, but of type `torch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To retrieve the number from the scaler, we use scaler.item method\n",
    "scaler.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector\n",
    "\n",
    "- A vector is a one-dimensional tensor but can contain many numbers.\n",
    "- It is flexible in what all it can represent.\n",
    "- For example, a single vector `[3,2]` could be used to represent `[bathrooms, bedrooms]` in our house or `[3,2,2]` could be used to represent `[bathrooms, bedrooms, car_spaces]` in our house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of a vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of a Vector\n",
    "vector.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thus we see that the vector is one-dimensional (like a 1D-array) [no. of square brackets]\n",
    "- Its shape is 2 because it has 2 elements in its array/vector or in its square brackets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix\n",
    "A matrix is flexible like a vector, just has more dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[3,4],\n",
    "                        [5,6]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(MATRIX.shape) #Shape is 2,2 cause of 2 elements in each vector\n",
    "print(MATRIX.ndim) # 2 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 3,  6,  9],\n",
       "         [ 2,  8, 10]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any higher dimension can also be created similiarly and is called a tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                      [3,6,9],\n",
    "                       [2,8,10]]])\n",
    "TENSOR                      # Given tensor represents [day of week, steak sales, no of ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(TENSOR.shape) #Shape goes outer to inner, thats why it returns 1,3,3\n",
    "print(TENSOR.ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "\n",
    "In ML, we hardly generate hardcoded tensors like these. But rather a ML model starts off with large random tensors of numbers and adjusts them to make the data look better\n",
    "\n",
    "### Essence\n",
    "`Start with data --> look at data --> update random numbers --> look at data --> update random numbers....`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1944, 0.4664, 0.8440, 0.9590],\n",
       "         [0.9030, 0.6523, 0.2269, 0.5426],\n",
       "         [0.3525, 0.3810, 0.5972, 0.0554]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor of size (3,4)\n",
    "rand_tensor = torch.rand(size=(3,4))\n",
    "rand_tensor, rand_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7846, 0.5648, 0.5865,  ..., 0.7889, 0.0196, 0.6634],\n",
      "         [0.0461, 0.7951, 0.6063,  ..., 0.0055, 0.0087, 0.9430],\n",
      "         [0.2289, 0.3440, 0.2999,  ..., 0.7185, 0.3451, 0.9886],\n",
      "         ...,\n",
      "         [0.8879, 0.9645, 0.4401,  ..., 0.0165, 0.3377, 0.9539],\n",
      "         [0.4487, 0.6370, 0.9277,  ..., 0.0736, 0.0055, 0.8208],\n",
      "         [0.5728, 0.0961, 0.3055,  ..., 0.9921, 0.7182, 0.7228]],\n",
      "\n",
      "        [[0.9414, 0.4570, 0.4185,  ..., 0.8165, 0.9186, 0.6070],\n",
      "         [0.8885, 0.0665, 0.0807,  ..., 0.1203, 0.5337, 0.5413],\n",
      "         [0.9315, 0.4849, 0.2729,  ..., 0.6598, 0.4061, 0.5451],\n",
      "         ...,\n",
      "         [0.3384, 0.5537, 0.0107,  ..., 0.1463, 0.5034, 0.0200],\n",
      "         [0.7138, 0.7953, 0.5236,  ..., 0.3994, 0.4343, 0.4478],\n",
      "         [0.6151, 0.4382, 0.7057,  ..., 0.6331, 0.1297, 0.2321]],\n",
      "\n",
      "        [[0.0679, 0.2860, 0.5341,  ..., 0.4046, 0.4913, 0.2484],\n",
      "         [0.7166, 0.0618, 0.5459,  ..., 0.6997, 0.7790, 0.0026],\n",
      "         [0.6875, 0.2783, 0.8471,  ..., 0.2355, 0.9336, 0.4411],\n",
      "         ...,\n",
      "         [0.7663, 0.0643, 0.7549,  ..., 0.4047, 0.8245, 0.8831],\n",
      "         [0.9356, 0.9548, 0.1319,  ..., 0.7215, 0.4831, 0.1717],\n",
      "         [0.9848, 0.7435, 0.6062,  ..., 0.1853, 0.8596, 0.2865]]])\n",
      "torch.Size([3, 224, 224])\n",
      "3\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Creating random tensor within the [3,224,224] image size\n",
    "rand_tensor = torch.rand(size = (3, 224, 224))\n",
    "print(rand_tensor) \n",
    "print(rand_tensor.shape)\n",
    "print(rand_tensor.ndim)\n",
    "print(rand_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of all zeroes\n",
    "tensor_zeroes = torch.zeros(size = (3,4))\n",
    "tensor_zeroes, tensor_zeroes.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of all ones\n",
    "tensor_ones = torch.ones(size = (3,4))\n",
    "tensor_ones, tensor_ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can create using torch.arange(start, end, step) like python ranges\n",
    "tensor_range = torch.arange(start = 0, end = 10, step = 1)\n",
    "tensor_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with zeros or ones in the same shape as input using zeros_like(input) & ones_like(input)\n",
    "tensor_sim = torch.zeros_like(input = tensor_range)\n",
    "tensor_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "`torch.tensor()` method has additional arguments for dtype (default is torch.float32), device (which uses default tensor type) and requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 6., 7.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other datatypes include for eg float16, float64, etc.\n",
    "tensor_mytype = torch.tensor([[3,6,7]],\n",
    "                                dtype=torch.float64)\n",
    "tensor_mytype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor : tensor([[0.9278, 0.8041, 0.4785, 0.3828],\n",
      "        [0.8234, 0.6541, 0.8517, 0.6904],\n",
      "        [0.5927, 0.9732, 0.3959, 0.5329]])\n",
      "Tensor Shape : torch.Size([3, 4])\n",
      "Tensor Datatype : torch.float32\n",
      "Tensor Device : cpu\n"
     ]
    }
   ],
   "source": [
    "# Getting Information from Tensors\n",
    "\n",
    "some_tensor = torch.rand(size=(3,4))\n",
    "\n",
    "print(f'Tensor : {some_tensor}')\n",
    "print(f'Tensor Shape : {some_tensor.shape}')\n",
    "print(f'Tensor Datatype : {some_tensor.dtype}')\n",
    "print(f'Tensor Device : {some_tensor.device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Tensors\n",
    "\n",
    "- Like numpy arrays, we have basic operations on these tensors like addition, subtraction, multiplication wherein on re-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = a @ a\n",
    "b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
